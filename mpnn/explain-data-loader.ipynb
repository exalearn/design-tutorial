{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a TF Data Loader\n",
    "This notebook shows how we go from serialized TFRecords to training batches. TF Data Loaders are created by defining a set of operations as a stream. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphsage.mpnn.data import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join('..', 'data', 'output', 'water_clusters.proto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading Records from Disk\n",
    "Our records are stored as serialized protobuf records. Origin of the stream of data will be to read from this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV1 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this loader produces a dataset of strings, which are the serialized data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(), dtype=string, numpy=b\"\\n\\xcb\\x02\\n\\x12\\n\\x06energy\\x12\\x08\\x12\\x06\\n\\x04\\xd4\\xfc\\x94\\xc2\\n\\x11\\n\\x08n_waters\\x12\\x05\\x1a\\x03\\n\\x01\\t\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01\\x1b\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01<\\n'\\n\\x04atom\\x12\\x1f\\x1a\\x1d\\n\\x1b\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\nH\\n\\x04bond\\x12@\\x1a>\\n<\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\x8c\\x01\\n\\x0cconnectivity\\x12|\\x1az\\nx\\x00\\x01\\x00\\x02\\x00\\x0b\\x01\\x00\\x01\\x06\\x02\\x00\\x03\\x04\\x03\\x05\\x03\\x07\\x04\\x03\\x05\\x03\\x05\\x18\\x06\\x01\\x06\\x07\\x06\\x08\\x07\\x03\\x07\\x06\\x08\\x06\\x08\\x0f\\t\\n\\t\\x0b\\t\\x13\\n\\t\\x0b\\x00\\x0b\\t\\x0c\\r\\x0c\\x0e\\x0c\\x16\\r\\x0c\\r\\x18\\x0e\\x0c\\x0e\\x0f\\x0f\\x08\\x0f\\x0e\\x0f\\x10\\x0f\\x11\\x10\\x0f\\x10\\x12\\x11\\x0f\\x11\\x15\\x12\\x10\\x12\\x13\\x12\\x14\\x12\\x19\\x13\\t\\x13\\x12\\x14\\x12\\x15\\x11\\x15\\x16\\x15\\x17\\x16\\x0c\\x16\\x15\\x17\\x15\\x18\\x05\\x18\\r\\x18\\x19\\x18\\x1a\\x19\\x12\\x19\\x18\\x1a\\x18\">"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance reasons, we are going to form these records into batches first before parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: (?,), types: tf.string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(2,), dtype=string, numpy=\n",
       "array([b'\\n\\x8a\\x03\\n\\x12\\n\\x06energy\\x12\\x08\\x12\\x06\\n\\x04F\\xf7\\xc6\\xc2\\n\\x11\\n\\x08n_waters\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01!\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01N\\n-\\n\\x04atom\\x12%\\x1a#\\n!\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\nZ\\n\\x04bond\\x12R\\x1aP\\nN\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\n\\xb3\\x01\\n\\x0cconnectivity\\x12\\xa2\\x01\\x1a\\x9f\\x01\\n\\x9c\\x01\\x00\\x01\\x00\\x02\\x00\\x13\\x01\\x00\\x01\\x1b\\x02\\x00\\x02\\x0c\\x03\\x04\\x03\\x05\\x03\\x08\\x03\\x1a\\x04\\x03\\x04\\x0f\\x05\\x03\\x05\\x0c\\x06\\x07\\x06\\x08\\x06\\r\\x06 \\x07\\x06\\x07\\x12\\x08\\x03\\x08\\x06\\t\\n\\t\\x0b\\t\\x1d\\n\\t\\n\\x15\\x0b\\t\\x0b\\x1e\\x0c\\x02\\x0c\\x05\\x0c\\r\\x0c\\x0e\\r\\x06\\r\\x0c\\x0e\\x0c\\x0f\\x04\\x0f\\x10\\x0f\\x11\\x10\\x0f\\x10\\x1b\\x11\\x0f\\x11\\x15\\x12\\x07\\x12\\x13\\x12\\x14\\x13\\x00\\x13\\x12\\x14\\x12\\x15\\n\\x15\\x11\\x15\\x16\\x15\\x17\\x16\\x15\\x17\\x15\\x17\\x18\\x18\\x17\\x18\\x19\\x18\\x1a\\x19\\x18\\x19\\x1e\\x1a\\x03\\x1a\\x18\\x1b\\x01\\x1b\\x10\\x1b\\x1c\\x1b\\x1d\\x1c\\x1b\\x1d\\t\\x1d\\x1b\\x1e\\x0b\\x1e\\x19\\x1e\\x1f\\x1e \\x1f\\x1e \\x06 \\x1e',\n",
       "       b'\\n\\x84\\x03\\n\\x12\\n\\x06energy\\x12\\x08\\x12\\x06\\n\\x04\\x7f\\x95\\xc6\\xc2\\n\\x11\\n\\x08n_waters\\x12\\x05\\x1a\\x03\\n\\x01\\x0b\\n\\x0f\\n\\x06n_atom\\x12\\x05\\x1a\\x03\\n\\x01!\\n\\x0f\\n\\x06n_bond\\x12\\x05\\x1a\\x03\\n\\x01L\\n-\\n\\x04atom\\x12%\\x1a#\\n!\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\x00\\x01\\x01\\nX\\n\\x04bond\\x12P\\x1aN\\nL\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\x01\\x01\\x00\\x00\\x00\\x00\\n\\xaf\\x01\\n\\x0cconnectivity\\x12\\x9e\\x01\\x1a\\x9b\\x01\\n\\x98\\x01\\x00\\x01\\x00\\x02\\x00\\x04\\x00\\x08\\x01\\x00\\x01\\x0f\\x02\\x00\\x03\\x04\\x03\\x05\\x03\\x16\\x04\\x00\\x04\\x03\\x05\\x03\\x06\\x07\\x06\\x08\\x06\\x14\\x06\\x1a\\x07\\x06\\x07\\t\\x08\\x00\\x08\\x06\\t\\x07\\t\\n\\t\\x0b\\t\\x10\\n\\t\\n\\x18\\x0b\\t\\x0b\\x1e\\x0c\\r\\x0c\\x0e\\x0c\\x11\\r\\x0c\\x0e\\x0c\\x0e\\x12\\x0f\\x01\\x0f\\x10\\x0f\\x11\\x10\\t\\x10\\x0f\\x11\\x0c\\x11\\x0f\\x12\\x0e\\x12\\x13\\x12\\x14\\x13\\x12\\x13\\x1e\\x14\\x06\\x14\\x12\\x15\\x16\\x15\\x17\\x15\\x19\\x16\\x03\\x16\\x15\\x17\\x15\\x18\\n\\x18\\x19\\x18\\x1a\\x18\\x1d\\x19\\x15\\x19\\x18\\x1a\\x06\\x1a\\x18\\x1b\\x1c\\x1b\\x1d\\x1b \\x1c\\x1b\\x1d\\x18\\x1d\\x1b\\x1e\\x0b\\x1e\\x13\\x1e\\x1f\\x1e \\x1f\\x1e \\x1b \\x1e'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a two member batch of arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to convert the batches of records into a set of tensors.\n",
    "\n",
    "To do so, you must define which elements of the protobuf message you would like to read from the object and define their types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_records(example_proto):\n",
    "    \"\"\"Parse data from the TFRecord\"\"\"\n",
    "    features = {\n",
    "        'energy': tf.io.FixedLenFeature([], tf.float32, default_value=np.nan),\n",
    "        'n_atom': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'n_bond': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'connectivity': tf.io.VarLenFeature(tf.int64),\n",
    "        'atom': tf.io.VarLenFeature(tf.int64),\n",
    "        'bond': tf.io.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    return tf.io.parse_example(example_proto, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this function to the data chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {atom: (?, ?), bond: (?, ?), connectivity: (?, ?), energy: (?,), n_atom: (?,), n_bond: (?,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, energy: tf.float32, n_atom: tf.int64, n_bond: tf.int64}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have Tensor objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing to Make MPNN-compatible batches\n",
    "Tensorflow now can understand the data types, but these data are not yet in a form we can use in our MPNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21f787f3d48>,\n",
       " 'bond': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21f7afb5c08>,\n",
       " 'connectivity': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x21f7b049388>,\n",
       " 'energy': <tf.Tensor: id=108, shape=(2,), dtype=float32, numpy=array([-98.59649, -98.24457], dtype=float32)>,\n",
       " 'n_atom': <tf.Tensor: id=109, shape=(2,), dtype=int64, numpy=array([33, 33], dtype=int64)>,\n",
       " 'n_bond': <tf.Tensor: id=110, shape=(2,), dtype=int64, numpy=array([78, 76], dtype=int64)>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our big issue is that the `SparseTensor` objects cannot be used in many Tensorflow operations. We need to convert them to Dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_batching(dataset):\n",
    "    \"\"\"Make the variable length arrays into RaggedArrays.\n",
    "    \n",
    "    Allows them to be merged together in batches\"\"\"\n",
    "    for c in ['atom', 'bond', 'connectivity']:\n",
    "        expanded = tf.expand_dims(dataset[c].values, axis=0, name=f'expand_{c}')\n",
    "        dataset[c] = tf.RaggedTensor.from_tensor(expanded)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {atom: (?, ?), bond: (?, ?), connectivity: (?, ?), energy: (?,), n_atom: (?,), n_bond: (?,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, energy: tf.float32, n_atom: tf.int64, n_bond: tf.int64}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records).map(prepare_for_batching)\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tf.RaggedTensor [[0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]]>,\n",
       " 'bond': <tf.RaggedTensor [[0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]>,\n",
       " 'connectivity': <tf.RaggedTensor [[0, 1, 0, 2, 0, 4, 0, 14, 0, 29, 1, 0, 1, 18, 2, 0, 3, 4, 3, 5, 3, 10, 4, 0, 4, 3, 5, 3, 5, 15, 6, 7, 6, 8, 6, 22, 6, 31, 7, 6, 8, 6, 8, 27, 9, 10, 9, 11, 9, 23, 9, 28, 10, 3, 10, 9, 11, 9, 12, 13, 12, 14, 12, 32, 13, 12, 14, 0, 14, 12, 15, 5, 15, 16, 15, 17, 16, 15, 16, 18, 17, 15, 17, 24, 18, 1, 18, 16, 18, 19, 18, 20, 19, 18, 19, 30, 20, 18, 20, 21, 21, 20, 21, 22, 21, 23, 21, 26, 22, 6, 22, 21, 23, 9, 23, 21, 24, 17, 24, 25, 24, 26, 25, 24, 26, 21, 26, 24, 27, 8, 27, 28, 27, 29, 28, 9, 28, 27, 29, 0, 29, 27, 30, 19, 30, 31, 30, 32, 31, 6, 31, 30, 32, 12, 32, 30, 0, 1, 0, 2, 0, 28, 0, 31, 1, 0, 1, 18, 2, 0, 3, 4, 3, 5, 3, 10, 3, 29, 4, 3, 4, 24, 5, 3, 5, 30, 6, 7, 6, 8, 6, 13, 7, 6, 8, 6, 8, 18, 9, 10, 9, 11, 9, 17, 9, 22, 10, 3, 10, 9, 11, 9, 11, 12, 12, 11, 12, 13, 12, 14, 13, 6, 13, 12, 14, 12, 14, 27, 15, 16, 15, 17, 15, 19, 15, 32, 16, 15, 17, 9, 17, 15, 18, 1, 18, 8, 18, 19, 18, 20, 19, 15, 19, 18, 20, 18, 21, 22, 21, 23, 21, 26, 22, 9, 22, 21, 23, 21, 24, 4, 24, 25, 24, 26, 25, 24, 26, 21, 26, 24, 27, 14, 27, 28, 27, 29, 28, 0, 28, 27, 29, 3, 29, 27, 30, 5, 30, 31, 30, 32, 31, 0, 31, 30, 32, 15, 32, 30]]>,\n",
       " 'energy': <tf.Tensor: id=295, shape=(2,), dtype=float32, numpy=array([-99.740135, -98.00737 ], dtype=float32)>,\n",
       " 'n_atom': <tf.Tensor: id=296, shape=(2,), dtype=int64, numpy=array([33, 33], dtype=int64)>,\n",
       " 'n_bond': <tf.Tensor: id=297, shape=(2,), dtype=int64, numpy=array([78, 76], dtype=int64)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data close to the form we need it, minus a few things:\n",
    "\n",
    "- We can't easily know which \"node\" corresponds to which training entry because we have stuck multiple graphs into the same batch\n",
    "- The `connectivity` array is the wrong shape. It is a 1D instead of Nx2 array\n",
    "- The node ids in the connectivity arrays are incorrect. Since we have merged multiple graphs, the node 0 of the second graph is no longer at position 0 in the `atom` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_graphs(batch):\n",
    "    \"\"\"Combine multiple graphs into a single network\"\"\"\n",
    "\n",
    "    # Compute the mappings from bond index to graph index\n",
    "    batch_size = tf.size(batch['n_atom'], name='batch_size')\n",
    "    mol_id = tf.range(batch_size, name='mol_inds')\n",
    "    batch['node_graph_indices'] = repeat(mol_id, batch['n_atom'], axis=0)\n",
    "    batch['bond_graph_indices'] = repeat(mol_id, batch['n_bond'], axis=0)\n",
    "\n",
    "    # Reshape the bond, connectivity, and node lists\n",
    "    for c in ['atom', 'bond', 'connectivity']:\n",
    "        batch[c] = batch[c].flat_values\n",
    "\n",
    "    # Reshape the connectivity matrix to (None, 2)\n",
    "    batch['connectivity'] = tf.reshape(batch['connectivity'], (-1, 2))\n",
    "\n",
    "    # Denote the shapes for the atom and bond matrices\n",
    "    #  Only an issue for 1.14, which cannot infer them it seems\n",
    "    for c in ['atom', 'bond']:\n",
    "        batch[c].set_shape((None,))\n",
    "\n",
    "    # Compute offsets for the connectivity matrix\n",
    "    offset_values = tf.cumsum(batch['n_atom'], exclusive=True)\n",
    "    offsets = repeat(offset_values, batch['n_bond'], name='offsets', axis=0)\n",
    "    batch['connectivity'] += tf.expand_dims(offsets, 1)\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ward6\\Miniconda3\\envs\\graphsage\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: {atom: (?,), bond: (?,), connectivity: (?, 2), energy: (?,), n_atom: (?,), n_bond: (?,), node_graph_indices: (?,), bond_graph_indices: (?,)}, types: {atom: tf.int64, bond: tf.int64, connectivity: tf.int64, energy: tf.float32, n_atom: tf.int64, n_bond: tf.int64, node_graph_indices: tf.int32, bond_graph_indices: tf.int32}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = tf.data.TFRecordDataset(data_file).shuffle(128).batch(2).map(parse_records).map(prepare_for_batching).map(combine_graphs)\n",
    "loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation converts our vectors into the right shape now. And, because we did all of these operations in Tensorflow, we can delegate these operations to the GPU and use Tensorflow's automated parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'atom': <tf.Tensor: id=645, shape=(63,), dtype=int64, numpy=\n",
       " array([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
       "       dtype=int64)>,\n",
       " 'bond': <tf.Tensor: id=646, shape=(148,), dtype=int64, numpy=\n",
       " array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>,\n",
       " 'connectivity': <tf.Tensor: id=648, shape=(148, 2), dtype=int64, numpy=\n",
       " array([[ 0,  1],\n",
       "        [ 0,  2],\n",
       "        [ 0, 10],\n",
       "        [ 1,  0],\n",
       "        [ 1, 12],\n",
       "        [ 2,  0],\n",
       "        [ 3,  4],\n",
       "        [ 3,  5],\n",
       "        [ 3, 16],\n",
       "        [ 3, 26],\n",
       "        [ 4,  3],\n",
       "        [ 4, 18],\n",
       "        [ 5,  3],\n",
       "        [ 5, 30],\n",
       "        [ 6,  7],\n",
       "        [ 6,  8],\n",
       "        [ 6, 22],\n",
       "        [ 6, 32],\n",
       "        [ 7,  6],\n",
       "        [ 8,  6],\n",
       "        [ 8,  9],\n",
       "        [ 9,  8],\n",
       "        [ 9, 10],\n",
       "        [ 9, 11],\n",
       "        [10,  0],\n",
       "        [10,  9],\n",
       "        [11,  9],\n",
       "        [12,  1],\n",
       "        [12, 13],\n",
       "        [12, 14],\n",
       "        [12, 31],\n",
       "        [13, 12],\n",
       "        [13, 21],\n",
       "        [14, 12],\n",
       "        [14, 18],\n",
       "        [15, 16],\n",
       "        [15, 17],\n",
       "        [15, 29],\n",
       "        [16,  3],\n",
       "        [16, 15],\n",
       "        [17, 15],\n",
       "        [18,  4],\n",
       "        [18, 14],\n",
       "        [18, 19],\n",
       "        [18, 20],\n",
       "        [19, 18],\n",
       "        [19, 24],\n",
       "        [20, 18],\n",
       "        [20, 27],\n",
       "        [21, 13],\n",
       "        [21, 22],\n",
       "        [21, 23],\n",
       "        [21, 25],\n",
       "        [22,  6],\n",
       "        [22, 21],\n",
       "        [23, 21],\n",
       "        [24, 19],\n",
       "        [24, 25],\n",
       "        [24, 26],\n",
       "        [25, 21],\n",
       "        [25, 24],\n",
       "        [26,  3],\n",
       "        [26, 24],\n",
       "        [27, 20],\n",
       "        [27, 28],\n",
       "        [27, 29],\n",
       "        [28, 27],\n",
       "        [29, 15],\n",
       "        [29, 27],\n",
       "        [30,  5],\n",
       "        [30, 31],\n",
       "        [30, 32],\n",
       "        [31, 12],\n",
       "        [31, 30],\n",
       "        [32,  6],\n",
       "        [32, 30],\n",
       "        [33, 34],\n",
       "        [33, 35],\n",
       "        [33, 41],\n",
       "        [33, 50],\n",
       "        [34, 33],\n",
       "        [34, 45],\n",
       "        [35, 33],\n",
       "        [35, 42],\n",
       "        [36, 37],\n",
       "        [36, 38],\n",
       "        [36, 49],\n",
       "        [36, 59],\n",
       "        [37, 36],\n",
       "        [37, 60],\n",
       "        [38, 36],\n",
       "        [38, 39],\n",
       "        [39, 38],\n",
       "        [39, 40],\n",
       "        [39, 41],\n",
       "        [40, 39],\n",
       "        [40, 60],\n",
       "        [41, 33],\n",
       "        [41, 39],\n",
       "        [42, 35],\n",
       "        [42, 43],\n",
       "        [42, 44],\n",
       "        [42, 47],\n",
       "        [43, 42],\n",
       "        [44, 42],\n",
       "        [44, 51],\n",
       "        [45, 34],\n",
       "        [45, 46],\n",
       "        [45, 47],\n",
       "        [45, 62],\n",
       "        [46, 45],\n",
       "        [46, 54],\n",
       "        [47, 42],\n",
       "        [47, 45],\n",
       "        [48, 49],\n",
       "        [48, 50],\n",
       "        [48, 53],\n",
       "        [49, 36],\n",
       "        [49, 48],\n",
       "        [50, 33],\n",
       "        [50, 48],\n",
       "        [51, 44],\n",
       "        [51, 52],\n",
       "        [51, 53],\n",
       "        [52, 51],\n",
       "        [52, 54],\n",
       "        [53, 48],\n",
       "        [53, 51],\n",
       "        [54, 46],\n",
       "        [54, 52],\n",
       "        [54, 55],\n",
       "        [54, 56],\n",
       "        [55, 54],\n",
       "        [55, 57],\n",
       "        [56, 54],\n",
       "        [57, 55],\n",
       "        [57, 58],\n",
       "        [57, 59],\n",
       "        [58, 57],\n",
       "        [59, 36],\n",
       "        [59, 57],\n",
       "        [60, 37],\n",
       "        [60, 40],\n",
       "        [60, 61],\n",
       "        [60, 62],\n",
       "        [61, 60],\n",
       "        [62, 45],\n",
       "        [62, 60]], dtype=int64)>,\n",
       " 'energy': <tf.Tensor: id=649, shape=(2,), dtype=float32, numpy=array([-97.53761, -87.39095], dtype=float32)>,\n",
       " 'n_atom': <tf.Tensor: id=650, shape=(2,), dtype=int64, numpy=array([33, 30], dtype=int64)>,\n",
       " 'n_bond': <tf.Tensor: id=651, shape=(2,), dtype=int64, numpy=array([76, 72], dtype=int64)>,\n",
       " 'node_graph_indices': <tf.Tensor: id=652, shape=(63,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>,\n",
       " 'bond_graph_indices': <tf.Tensor: id=647, shape=(148,), dtype=int32, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
